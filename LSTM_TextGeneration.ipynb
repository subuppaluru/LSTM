{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_TextGeneration.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMe8i/4zKoCOB3vpCrShkEu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/subuppaluru/LSTM/blob/main/LSTM_TextGeneration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HCTL49BW8h1p"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load ascii text and covert to lowercase\n",
        "filename = \"wonderland.txt\"\n",
        "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
        "raw_text = raw_text.lower()"
      ],
      "metadata": {
        "id": "MjpCONWH-IPw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create mapping of unique chars to integers\n",
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))"
      ],
      "metadata": {
        "id": "SRiCvuA4-RYe"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize the loaded data\n",
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print(\"Total Characters: \", n_chars)\n",
        "print(\"Total Vocab: \", n_vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqP_JNEq-Vqe",
        "outputId": "eb82596c-e869-4a92-9103-8ea8649f03d6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Characters:  163779\n",
            "Total Vocab:  58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "\tseq_in = raw_text[i:i + seq_length]\n",
        "\tseq_out = raw_text[i + seq_length]\n",
        "\tdataX.append([char_to_int[char] for char in seq_in])\n",
        "\tdataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "print (\"Total Patterns: \", n_patterns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_nCNRLa-iDw",
        "outputId": "94901dbe-1aaf-4635-a8b5-47235b4ea1e6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Patterns:  163679\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reshape X to be [samples, time steps, features]\n",
        "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "# normalize\n",
        "X = X / float(n_vocab)\n",
        "# one hot encode the output variable\n",
        "y = np_utils.to_categorical(dataY)"
      ],
      "metadata": {
        "id": "Of5WOPln_LpA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model"
      ],
      "metadata": {
        "id": "LWaGh4Yz_c5-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "# load the network weights\n",
        "#filename = \"weights-improvement-19-1.9435.hdf5\"\n",
        "#model.load_weights(filename)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "metadata": {
        "id": "94dITLhF_b8A"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = \"weights-improvement-19-1.9435.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath,monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]\n"
      ],
      "metadata": {
        "id": "GJgZPYXHBRKg"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqtQwhPRBT8A",
        "outputId": "76e1edb3-ed83-47f0-f060-7d9eae0038f5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_3 (LSTM)               (None, 256)               264192    \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 58)                14906     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 279,098\n",
            "Trainable params: 279,098\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the model\n",
        "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCFcR2USBTRo",
        "outputId": "6a2c28f5-0516-4790-d0bf-212b0e25ab6f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1279/1279 [==============================] - ETA: 0s - loss: 2.9908\n",
            "Epoch 00001: loss improved from inf to 2.99080, saving model to weights-improvement-19-1.9435.hdf5\n",
            "1279/1279 [==============================] - 672s 524ms/step - loss: 2.9908\n",
            "Epoch 2/20\n",
            "1279/1279 [==============================] - ETA: 0s - loss: 2.8164\n",
            "Epoch 00002: loss improved from 2.99080 to 2.81643, saving model to weights-improvement-19-1.9435.hdf5\n",
            "1279/1279 [==============================] - 678s 530ms/step - loss: 2.8164\n",
            "Epoch 3/20\n",
            "1279/1279 [==============================] - ETA: 0s - loss: 2.7260\n",
            "Epoch 00003: loss improved from 2.81643 to 2.72598, saving model to weights-improvement-19-1.9435.hdf5\n",
            "1279/1279 [==============================] - 679s 531ms/step - loss: 2.7260\n",
            "Epoch 4/20\n",
            "1279/1279 [==============================] - ETA: 0s - loss: 2.6551\n",
            "Epoch 00004: loss improved from 2.72598 to 2.65512, saving model to weights-improvement-19-1.9435.hdf5\n",
            "1279/1279 [==============================] - 678s 530ms/step - loss: 2.6551\n",
            "Epoch 5/20\n",
            "1279/1279 [==============================] - ETA: 0s - loss: 2.5952\n",
            "Epoch 00005: loss improved from 2.65512 to 2.59519, saving model to weights-improvement-19-1.9435.hdf5\n",
            "1279/1279 [==============================] - 676s 529ms/step - loss: 2.5952\n",
            "Epoch 6/20\n",
            "1279/1279 [==============================] - ETA: 0s - loss: 2.5418\n",
            "Epoch 00006: loss improved from 2.59519 to 2.54180, saving model to weights-improvement-19-1.9435.hdf5\n",
            "1279/1279 [==============================] - 675s 527ms/step - loss: 2.5418\n",
            "Epoch 7/20\n",
            "1279/1279 [==============================] - ETA: 0s - loss: 2.4923\n",
            "Epoch 00007: loss improved from 2.54180 to 2.49225, saving model to weights-improvement-19-1.9435.hdf5\n",
            "1279/1279 [==============================] - 671s 525ms/step - loss: 2.4923\n",
            "Epoch 8/20\n",
            "1279/1279 [==============================] - ETA: 0s - loss: 2.4477\n",
            "Epoch 00008: loss improved from 2.49225 to 2.44772, saving model to weights-improvement-19-1.9435.hdf5\n",
            "1279/1279 [==============================] - 671s 525ms/step - loss: 2.4477\n",
            "Epoch 9/20\n",
            "1279/1279 [==============================] - ETA: 0s - loss: 2.4034\n",
            "Epoch 00009: loss improved from 2.44772 to 2.40344, saving model to weights-improvement-19-1.9435.hdf5\n",
            "1279/1279 [==============================] - 662s 517ms/step - loss: 2.4034\n",
            "Epoch 10/20\n",
            "1279/1279 [==============================] - ETA: 0s - loss: 2.3639\n",
            "Epoch 00010: loss improved from 2.40344 to 2.36393, saving model to weights-improvement-19-1.9435.hdf5\n",
            "1279/1279 [==============================] - 662s 517ms/step - loss: 2.3639\n",
            "Epoch 11/20\n",
            "1279/1279 [==============================] - ETA: 0s - loss: 2.3240\n",
            "Epoch 00011: loss improved from 2.36393 to 2.32403, saving model to weights-improvement-19-1.9435.hdf5\n",
            "1279/1279 [==============================] - 665s 520ms/step - loss: 2.3240\n",
            "Epoch 12/20\n",
            "1279/1279 [==============================] - ETA: 0s - loss: 2.2883\n",
            "Epoch 00012: loss improved from 2.32403 to 2.28828, saving model to weights-improvement-19-1.9435.hdf5\n",
            "1279/1279 [==============================] - 655s 512ms/step - loss: 2.2883\n",
            "Epoch 13/20\n",
            "1279/1279 [==============================] - ETA: 0s - loss: 2.2508\n",
            "Epoch 00013: loss improved from 2.28828 to 2.25080, saving model to weights-improvement-19-1.9435.hdf5\n",
            "1279/1279 [==============================] - 655s 512ms/step - loss: 2.2508\n",
            "Epoch 14/20\n",
            "1279/1279 [==============================] - ETA: 0s - loss: 2.2196\n",
            "Epoch 00014: loss improved from 2.25080 to 2.21960, saving model to weights-improvement-19-1.9435.hdf5\n",
            "1279/1279 [==============================] - 669s 523ms/step - loss: 2.2196\n",
            "Epoch 15/20\n",
            "1279/1279 [==============================] - ETA: 0s - loss: 2.1882\n",
            "Epoch 00015: loss improved from 2.21960 to 2.18824, saving model to weights-improvement-19-1.9435.hdf5\n",
            "1279/1279 [==============================] - 662s 518ms/step - loss: 2.1882\n",
            "Epoch 16/20\n",
            "1279/1279 [==============================] - ETA: 0s - loss: 2.1575\n",
            "Epoch 00016: loss improved from 2.18824 to 2.15749, saving model to weights-improvement-19-1.9435.hdf5\n",
            "1279/1279 [==============================] - 670s 524ms/step - loss: 2.1575\n",
            "Epoch 17/20\n",
            "1279/1279 [==============================] - ETA: 0s - loss: 2.1288\n",
            "Epoch 00017: loss improved from 2.15749 to 2.12879, saving model to weights-improvement-19-1.9435.hdf5\n",
            "1279/1279 [==============================] - 667s 522ms/step - loss: 2.1288\n",
            "Epoch 18/20\n",
            "1279/1279 [==============================] - ETA: 0s - loss: 2.1036\n",
            "Epoch 00018: loss improved from 2.12879 to 2.10360, saving model to weights-improvement-19-1.9435.hdf5\n",
            "1279/1279 [==============================] - 653s 510ms/step - loss: 2.1036\n",
            "Epoch 19/20\n",
            "1279/1279 [==============================] - ETA: 0s - loss: 2.0749\n",
            "Epoch 00019: loss improved from 2.10360 to 2.07486, saving model to weights-improvement-19-1.9435.hdf5\n",
            "1279/1279 [==============================] - 669s 523ms/step - loss: 2.0749\n",
            "Epoch 20/20\n",
            "1279/1279 [==============================] - ETA: 0s - loss: 2.0520\n",
            "Epoch 00020: loss improved from 2.07486 to 2.05196, saving model to weights-improvement-19-1.9435.hdf5\n",
            "1279/1279 [==============================] - 668s 522ms/step - loss: 2.0520\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f418c96eb10>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "int_to_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "metadata": {
        "id": "fSJAfa_M1kkf"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pick a random seed\n",
        "import sys\n",
        "start = numpy.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[start]\n",
        "print (\"Seed:\")\n",
        "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
        "# generate characters\n",
        "for i in range(1000):\n",
        "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "\tx = x / float(n_vocab)\n",
        "\tprediction = model.predict(x, verbose=0)\n",
        "\tindex = numpy.argmax(prediction)\n",
        "\tresult = int_to_char[index]\n",
        "\tseq_in = [int_to_char[value] for value in pattern]\n",
        "\tsys.stdout.write(result)\n",
        "\tpattern.append(index)\n",
        "\tpattern = pattern[1:len(pattern)]\n",
        "print (\"\\nDone.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHMrpJTkCDcg",
        "outputId": "501d96d2-cd3d-4ee5-92a1-f6726b1c8f25"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed:\n",
            "\" it's high time you were all in bed!'\n",
            "on various pretexts they all moved off, and alice was soon left \"\n",
            " the was oo and toene to ae infe to ae inre, and the wai qooe th the was ani the was oate anr the was oo and the tam oh the war of the war oate and the was oo and the tame th the waide \n",
            "ani eer a little sooell to ced to the waite and thet iar fare and the waite  and tou thit io a lange hireer, and the weile taid to the woide ' \n",
            "'ih i dan't teee the borme, in a cet ' said alice, ''that s tee sai ' sheue taed to herself, ''what so seke the girse wornd ' she seitg rabbit aare lere anrce. \n",
            "'ie iou't thte the moce turtle so ae in a cat,' said the caterpillar.\n",
            "\n",
            "'ieve you gad to tae ' said the manch hare.\n",
            "\n",
            "'ie d dene to teee ' said the monen, and the wait on an aeree an an ffreen, and the waited thth theee th the waale 'thet io thr the wai if a cotr of the sare an the crele, \n",
            "'the cir tat tha kart wireg ' shi seidg tert ontelely, 'in a lerg hf wou toeek the woid ' \n",
            "'                                                                                                  \n",
            "                             \n",
            "Done.\n"
          ]
        }
      ]
    }
  ]
}